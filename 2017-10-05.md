# Apollo GraphQL Nodejs
One of the reasons by which I decided to create this post is because first of all I think that GraphQL as a middleware backend technology nowadays it has been getting very popular by the open source community and second because as a Developer it is worth knowing what are the best practices to build a backend project from scrach with the porpose of having a very good and flexible API tool taking into account technologies like Nodejs, Graphql and Apollo.

I'm going to take for granted in this post technologies like Nodejs and GraphQL, however I'm going to give a more detailed explanation about Apollo before we get started.

# What is Apollo?
This is as its website points out a very flexible and rubust GraphQL client for production ready applications and also supports a set of frontend technologies like React, React Native, Angular, Swift (iOS), Java (Android) and Plain Javascript (Vanilla JS)

It also works as a backend technology, where the Apollo community has built a number of helper libraries being two out of the most popular graphql-tools and apollo-server.

The library graphql-tools is used to build from scratch a GraphQL project allowing the developer to combine all Queries, Mutations and Subscriptions in one executable Schema. On the other hand 

La libreria graphql-tools sirve para crear desde cero un proyecto GraphQL con las mejores practicas de estructura de archivos y a la vez haciendo uso del lenguaje de schemas de GraphQL para sacar el maximo provecho de esta tecnologia. Por otro lado tambien se usa para poder crear mocks de datos ya sea para el tiempo de desarrollo como para pruebas

La libreria apollo-server es un servidor Nodejs que se puede usar en producción y que soporta otras librerias como Express, Connect, Hapi, Koa entre otros servidores HTTP Nodejs. Por otro lado apollo-server trabaja con otros clientes GraphQL como Relay, Looka
entro otros.

# Creación de la arquitectura base
Para poder comenzar a crear tu propio proyecto API backend, estos pasos nos ayudará a generar toda la estructura de archivos, eso quiere decir que al final tendremos una arquitectura base para poder crear facilmente Schemas, Resolvers, Models y Connectors y que sean consumibles por medio de un endpoint para cualquier desarrollador

Entonces lo primero que haremos será crear una carpeta en donde va a estar nuestro proyecto y luego instalamos las herramientas así:

```
$ mkdir belatrix-api
$ cd belatrix-api
$ npm init -y
$ npm install --save graphql-tools graphql apollo-server-express body-parser compression cors express lodash dotenv
$ npm install --save-dev nodemon babel-cli babel-core babel-preset-es2015 babel-preset-stage-2 babel-register
```

Luego para tener datos de ejemplo, a manera de base de datos, creamos el siguiente archivo con el siguiente contenido en la raiz del proyecto:

```
# data.js
export const authors = [
  { id: 1, firstName: 'Carlos', lastName: 'Guzman' },
  { id: 2, firstName: 'Diego', lastName: 'Barrero' },
  { id: 3, firstName: 'Juan', lastName: 'Cortes' },
];

export const posts = [
  { id: 1, authorId: 1, title: 'Curso de GraphQL', votes: 2 },
  { id: 2, authorId: 2, title: 'Introduccion a Nodejs', votes: 3 },
  { id: 3, authorId: 2, title: 'Programacion Funcional', votes: 1 },
  { id: 4, authorId: 3, title: 'Curso de React Native', votes: 7 },
];
```

Luego podemos crear la siguiente estructura de archivos
```
.env
data.js
/api
├── index.js
├── schema.js
├── server.js
└── /sql
    ├── connector.js
    ├── models.js
    └── schema.js
```

# Configuración global
Lo siguiente es crear el archivo .env que tendrá las variables de entorno que queramos para la aplicación, como por ejemplo el puerto por donde escucha el servidor nodejs así:
```
PORT=3011
```

Ahora procedemos a crear nuestro servidor Nodejs con el siguiente contenido dentro del archivo /api/index.js, en este archivo importamos la función run que a su vez nos permitirá pasar cualquier variable de ambiente que necesitemos para ejecutar el servidor

```
# /api/index.js
import dotenv from "dotenv";
import { run } from './server';

dotenv.config({ silent: true });
run(process.env);
```

# Configuración del servidor Nodejs
Luego dentro del archivo /api/server.js ingresamos los siguientes imports:
```
# /api/server.js
import express from "express";
import { graphqlExpress, graphiqlExpress } from "apollo-server-express";
import bodyParser from "body-parser";
import { isString } from "lodash";
import { createServer } from "http";

import { Authors, Posts } from "./sql/models";

import schema from "./schema";

```

En estos imports se puede notar el uso de los middleware graphqlExpress y graphiqlExpress los cuales nos servirán para dar soporte a graphql desde nodejs

Tambien es importante mencionar los imports de los modelos Authors y Posts los cuales contienen toda la interacción con el modelo ya sea por base de datos, alguna api tercera o simplemente la interacción de datos en un archivo JSON.

El import de schema es el que contiene todas las definiciones de queries, mutations y subscriptions en graphql.

Ahora continuamos creando la función run dentro del mismo archivo así:

```
# /api/server.js
...

export const run = ({
  PORT: portFromEnv = 3010
} = {}) => {

}
```

En este caso solo estamos capturando la variable PORT desde las variables de ambiente, pero tambien podemos importar variables como API keys o variables globales que se necesiten para la aplicación de la misma forma.

Luego dentro de la función run configuramos el puerto, creamos la aplicación express, y se le da soporte al formato JSON

```
# /api/server.js
...

const port = isString(portFromEnv) ?
    parseInt(portFromEnv, 10) : portFromEnv;

const app = express();

app.use(bodyParser.urlencoded({ extended: true }));
app.use(bodyParser.json());

...
```

Luego configuramos los servicios de graphql y graphiql así

```
# /api/server.js
...

app.use("/graphiql", graphiqlExpress({
  endpointURL: "/graphql"
}));

app.use("/graphql", graphqlExpress(req => {
  const query = req.query.query || req.body.query;
  if (query && query.length > 2000) {
    throw new Error("Query too large.");
  }

  return {
    schema,
    context: {
      Authors: new Authors(),
      Posts: new Posts()
    },
  };
}));
```

En donde el endpoint de la herramienta graphiql se configura en la url http://localhost:3011/graphql y el schema GraphQL con los Queries, Mutations y Subscriptions con dos modelos llamados Authors y Posts son configurados tambien.

Luego se debe crear el servidor y escuchar en el puerto indicado, de la siguiente forma:

```
# /api/server.js
...

const server = createServer(app);

server.listen(port, () => {
  console.log(`API Server is now running on http://localhost:${port}`);
});
```

# Configuración del schema principal

```
# /api/schema.js
import { merge } from "lodash";
import { makeExecutableSchema } from "graphql-tools";
import { schema as sqlSchema, resolvers as sqlResolvers } from "./sql/schema.js";

```

En los anteriores imports, se hace uso de la funcionalidad merge de lodash para hacer merge de todos los resolvers que se tengan. Tambien se hace import de la herramienta makeExecutableSchema para poder combinar la lista de schemas con la lista de resolvers.

Luego en el mismo archivo definimos los tipos que se van a usar y los resolvers que son los encargados de comunicarse con el modelo, de la siguiente forma:

```
# /api/schema.js
...

const rootSchema = [`
  type Query {
    posts: [Post]
    author(id: Int!): Author
  }

  type Mutation {
    upvotePost (
      postId: Int!
    ): Post
  }
`];
```

Luego se definen los resolvers así:

```
# /api/schema.js
...

const rootResolvers = {
  Query: {
    posts: (_, params, context) => context.Posts.getPosts(),
    author: (_, { id }, context) => context.Authors.getAuthorById(id)
  },
  Mutation: {
    upvotePost: (_, { postId }, context) => context.Posts.upVotePost(postId)
  }
};
```

En donde el primer query resolver obtiene toda la lista de posts y el segundo obtiene la informacion de un Author por su id. En cuando a las mutaciones solo se creó una llamada upvotePost, la cual valora un post con un like.

y por ultimo se hace merge de los resolvers y se unen los schemas para poder crear el schema ejecutable de GraphQL.

```
# /api/schema.js
...

const schema = [...rootSchema, ...sqlSchema];
const resolvers = merge(rootResolvers, sqlResolvers);

const executableSchema = makeExecutableSchema({
  typeDefs: schema,
  resolvers,
});

export default executableSchema;
```

# Configuración del schema secundario
El schema secundario tendrá los resolvers y schemas que pertenecen a cada modelo, en este caso son los modelos de Author y Post, y se puede crear el archivo con el siguiente contenido

```
# /api/sql/schema.js

export const schema = [`
  type Author {
    id: Int!
    firstName: String
    lastName: String
    posts: [Post] # lista de posts por autor
  }
  type Post {
    id: Int!
    title: String
    author: Author
    votes: Int
  }
`];

export const resolvers = {
  Author: {
    posts: (author, _, context) => context.Posts.getPostsByAuthorId(author.id)
  },
  Post: {
    author: (post, _, context) => context.Authors.getAuthorById(post.authorId),
  },
};
```

En donde se crean dos tipos, uno llamado Author con sus respectivos campos y otro llamado Post. Por otro lado los resolvers que se usan acá, son para consultar la lista de posts segun el id del autor y obtener la información de un autor segun su propio id


# Configuración de los modelos
Este es el archivo que se encarga de tener la logica de negocio e interacción con la fuete de datos, como lo puede ser por medio de un framework de base de datos, o un api tercero, o simplemente un archivo JSON o un objeto Javascript como lo es en este caso.

para ello, se crea el archivo ```/api/sql/models.js``` y en el se hacen primero los imports

```
# /api/sql/models.js
import { find, filter } from "lodash";

import connector from "./connector";
const { authors, posts } = connector();

...
```

Con esto se importa la libreria de lodash para poder hacer filtros y buscar objetos desde arrays y tambien usar un conector que en este caso simplemente devuelve dos arrays, que son authors y posts.

Por otro lado se crean los modelos como clases, y en este caso se crean la clase Authors y la clase Posts y con ellas su logica de negocio en sus funciones.

```
# /api/sql/models.js
...

export class Posts {
  getPosts() {
    return posts;
  }

  upVotePost(postId) {
    const post = find(posts, { id: postId });
    if (!post) {
      throw new Error(`Couldn't find post with id ${postId}`);
    }
    post.votes += 1;
    return post;
  }

  getPostsByAuthorId(authorId) {
    return filter(posts, { authorId });
  }
}

export class Authors {
  getAuthorById(id) {
    return find(authors, { id });
  }
}
```

# Configuración del connector
La idea del connector es tener un intermediario que pueda devolver ya sea un objeto con las funcionalidades de acceso a los datos y que ademas pueda ser configurable por ambiente, ya sea por que tiene una url, api keys o una ruta de base de datos, en este caso solo se importa un archivo que expone un objeto javascript el cual contiene los datos que necesitamos así:

```
import { authors, posts } from "../../data.js";

export default () => ({ authors, posts });
```

# Ejecución del proyecto
Para poder ejecutar el proyecto, es sugerible hacerlo a traves
de npm, con las siguiente configuración de scripts
```
# package.json
...
"scripts": {
  "start": "babel-node api/index.js",
  "dev": "nodemon api/index.js --watch api --exec babel-node"
}
...
```

una vez tengas listo la configuración de npm, puedes ejecutar el proyecto así:

```
$ npm run dev
```

Luego aparecerá un mesaje por consola que dirá lo siguiente:

```
API Server is now running on http://localhost:3010
```

luego para poder ver los schemas funcionando puedes dirigirte a la url http://localhost:3010/graphql desde un navegador web, eso te mostrará la interfaz para poder hacer queries y mutations
